# Copy to your own private env file (do NOT commit secrets):
# - repo-root: .env.local   (preferred)
# - or backend/.env

# ----------------------------
# Local development (docker-compose)
# ----------------------------
NEO4J_USER=neo4j
NEO4J_PASSWORD=change-me
NEO4J_URI=bolt://localhost:7687

# Optional test-only Neo4j profile (used by tests/test_graph_scoping_invariants.py)
# If omitted, the test falls back to NEO4J_URI/NEO4J_USER/NEO4J_PASSWORD.
NEO4J_TEST_URI=bolt://localhost:7687
NEO4J_TEST_USER=neo4j
NEO4J_TEST_PASSWORD=
NEO4J_TEST_DATABASE=neo4j
# RUN_GRAPH_SCOPING_TESTS=true to force-run, false to force-skip, unset to auto-detect.
RUN_GRAPH_SCOPING_TESTS=

BRAINWEB_API_BASE=http://127.0.0.1:8000

# ----------------------------
# Web Search / Live Data
# ----------------------------
# Exa is used for real-time web/document search + extraction
EXA_API_KEY=
# Stock quotes use Yahoo Finance public quote endpoint (no API key required by default).
# Optional: override the default config-driven routing catalog (aliases/providers/macros)
# WEB_SEARCH_ROUTING_CONFIG_PATH=/absolute/path/to/web_search_routing_config.json

# Disable private integrations by default
NOTION_API_KEY=
NOTION_DATABASE_IDS=
ENABLE_NOTION_AUTO_SYNC=false

# ----------------------------
# Authentication
# ----------------------------
# Secret key for JWT token signing (required for production)
# Generate a secure random string: openssl rand -hex 32
API_TOKEN_SECRET=

# ----------------------------
# Environment
# ----------------------------
NODE_ENV=development

AWS_REGION=us-east-1

# ----------------------------
# Browser Use Cloud API
# ----------------------------
BROWSER_USE_API_KEY=
BROWSER_USE_CONFUSION_SKILL_ID=
BROWSER_USE_BASE=https://api.browser-use.com/api/v2

# ----------------------------
# Storage Configuration (Resource Files)
# ----------------------------
# Storage backend: "local" (default, no cost) or "s3" (for production scale)
STORAGE_BACKEND=local
# S3 configuration (only needed if STORAGE_BACKEND=s3)
S3_BUCKET=
S3_REGION=us-east-1
S3_PREFIX=resources

# ----------------------------
# Qdrant Vector Database (for semantic search)
# ----------------------------
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=concepts
USE_QDRANT=true

# ----------------------------
# PostgreSQL + TimescaleDB (for event store)
# ----------------------------
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=brainweb
POSTGRES_USER=brainweb
POSTGRES_PASSWORD=brainweb
EVENTS_POSTGRES=false  # Set to true to use PostgreSQL instead of SQLite

# ----------------------------
# Redis (for caching)
# ----------------------------
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
USE_REDIS=true

# ----------------------------
# Sentry (optional)
# ----------------------------
SENTRY_DSN=
SENTRY_DSN_BACKEND=
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.0
SENTRY_PROFILES_SAMPLE_RATE=0.0
RELEASE=
GIT_SHA=

# ----------------------------
# Observability ingest (optional)
# ----------------------------
# Vercel Log Drains can POST logs to the backend and then Promtail will ship them to Loki.
# Endpoint: POST /observability/vercel/logs
VERCEL_LOG_DRAIN_SECRET=
# Dev-only: allow ingest without signed requests (NOT recommended in production).
VERCEL_LOG_DRAIN_ALLOW_INSECURE=false
